{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'googleapiclient'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogleapiclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscovery\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymongo\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsycopg2\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'googleapiclient'"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pymongo\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "### API connection\n",
    "\n",
    "def ApiConnect():\n",
    "    api_ID = \"AIzaSyBDVNvvTIxEk90R0rPat4lGTRrJDmCk-e4\"\n",
    "    api_service_name =\"Youtube\"\n",
    "    api_version_name = \"v3\"\n",
    "    youtube = build(api_service_name, api_version_name,developerKey=api_ID )\n",
    "    return youtube\n",
    "\n",
    "youtube = ApiConnect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "science with sam: UChGd9JY4yMegY6PxqpBjpRA\n",
    "mr gk:  UC5cY198GU1MQMIPJgMkCJ_Q\n",
    "tbp:    UCy1lBBbXhtfzugF_LK2b6Yw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get channel information\n",
    "def get_channel_info(channel_id):\n",
    "    request = youtube.channels().list(\n",
    "    part = \"snippet,ContentDetails,statistics\",\n",
    "    id = channel_id \n",
    "    )\n",
    "\n",
    "    response = request.execute()\n",
    "\n",
    "    for i in response['items']:\n",
    "        data=dict(Channel_Name = i[\"snippet\"][\"title\"],\n",
    "                Channel_ID = i[\"id\"],#here channel id is the column in the table we are creating from channel info\n",
    "                Views=i[\"statistics\"][\"viewCount\"],\n",
    "                Subscribers = i[\"statistics\"][\"subscriberCount\"],\n",
    "                Total_videos=i[\"statistics\"][\"videoCount\"],\n",
    "                Channel_Description=i[\"snippet\"][\"description\"],\n",
    "                Playlist_Id=i[\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"])##storing the extracted data in dictionary format --mongodb only stores data in json format\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get video ids\n",
    "def get_video_ids(channel_id):\n",
    "    video_ids= []\n",
    "    response = youtube.channels().list(id=channel_id,\n",
    "                                    part = 'contentDetails').execute()\n",
    "    Playlist_Id=response['items'][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "    \n",
    "    next_page_token = None\n",
    "    while True:\n",
    "        response1=youtube.playlistItems().list(\n",
    "                                                part='snippet',\n",
    "                                                playlistId=Playlist_Id,\n",
    "                                                maxResults=50,\n",
    "                                                pageToken = next_page_token).execute()\n",
    "        \n",
    "        for i in range(len(response1['items'])):\n",
    "            video_ids.append(response1['items'][i]['snippet']['resourceId']['videoId'])\n",
    "        next_page_token= response1.get('nextPageToken')\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get video information\n",
    "def get_video_info(video_ids):\n",
    "    video_data=[]\n",
    "\n",
    "    for video_id in video_ids:\n",
    "        request=youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        for  item in response['items']:\n",
    "            data=dict(channel_Name=item['snippet']['channelTitle'],\n",
    "                    channel_Id=item['snippet']['channelId'],\n",
    "                    Video_Id=item['id'],\n",
    "                    Video_Title=item['snippet']['title'],\n",
    "                    Tags=item['snippet'].get('tags'),\n",
    "                    Thumnail=item['snippet']['thumbnails']['default']['url'],\n",
    "                    Description=item.get('description'),\n",
    "                    Published_Date=item['snippet']['publishedAt'],\n",
    "                    Duration=item['contentDetails']['duration'],\n",
    "                    Views=item['statistics'].get('viewCount'),\n",
    "                    Likes=item['statistics'].get('likeCount'),\n",
    "                    Comments=item['statistics'].get('commentCount'),\n",
    "                    FavoriteCount=item['statistics']['favoriteCount'],\n",
    "                    Definition=item['contentDetails']['definition'],\n",
    "                    Caption_Status=item['contentDetails']['caption']\n",
    "                    )\n",
    "            video_data.append(data)\n",
    "\n",
    "    return video_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get comment inormation\n",
    "def get_comment_info(video_ids):\n",
    "    Comment_data=[]\n",
    "    try:\n",
    "        for video_id in video_ids:\n",
    "            request=youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=50\n",
    "            )\n",
    "            response=request.execute()\n",
    "\n",
    "            for item in response['items']:\n",
    "                data=dict(Comment_Id=item['snippet']['topLevelComment']['id'],\n",
    "                        Video_Id=item['snippet']['topLevelComment']['snippet']['videoId'],\n",
    "                        Comment_Text=item['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
    "                        Comment_Author=item['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
    "                        Comment_Published=item['snippet']['topLevelComment']['snippet']['publishedAt'])\n",
    "                Comment_data.append(data)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return Comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_playlist_details\n",
    "def get_playlist_details(channel_id):\n",
    "    next_page_token=None\n",
    "    All_data=[]\n",
    "    while True:\n",
    "        request=youtube.playlists().list(\n",
    "            part='snippet,contentDetails',\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        response=request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            data=dict(Playlist_Id=item['id'],\n",
    "                    Title=item['snippet']['title'],\n",
    "                    Channel_Id=item['snippet']['channelId'],\n",
    "                    Channel_Name=item['snippet']['channelTitle'],\n",
    "                    PublishedAt=item['snippet']['publishedAt'],\n",
    "                    Videocount=item['contentDetails']['itemCount'])\n",
    "            All_data.append(data)\n",
    "\n",
    "        next_page_token=response.get('nextPageToken')\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "\n",
    "    return All_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload to mongodb\n",
    "\n",
    "client=pymongo.MongoClient(\"mongodb+srv://yuva0398:yuva@cluster0.jwuol0q.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db=client[\"Youtube_data\"]\n",
    "\n",
    "# coll1=db[\"Channel_details\"](to test the db creation in mongo db)\n",
    "# x={\"name\":\"leo\",\"year\":2023}\n",
    "# coll1.insert_one(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_details(channel_id):\n",
    "    ch_details= get_channel_info(channel_id)\n",
    "    vi_ids= get_video_ids(channel_id)\n",
    "    vi_details= get_video_info(vi_ids)\n",
    "    Com_details= get_comment_info(vi_ids)\n",
    "    pl_details = get_playlist_details(channel_id)\n",
    "\n",
    "    coll1=db[\"channel_details\"]\n",
    "    coll1.insert_one({\"channel_information\":ch_details, \"playlist_information\":pl_details, \n",
    "                      \"video_information\":vi_details, \"comment_information\":Com_details})\n",
    "    \n",
    "    return \"upload completed successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert = channel_details('UCy1lBBbXhtfzugF_LK2b6Yw')\n",
    "\n",
    "# science with sam: UChGd9JY4yMegY6PxqpBjpRA\n",
    "# mr gk:  UC5cY198GU1MQMIPJgMkCJ_Q\n",
    "# tbp:    UCy1lBBbXhtfzugF_LK2b6Yw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table creation for channels,playlist,videos,comments\n",
    "def channels_table():\n",
    "    mydb=psycopg2.connect(host=\"localhost\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"12345\",\n",
    "                        database=\"youtube_data\",\n",
    "                        port=\"5432\")\n",
    "    cursor=mydb.cursor()\n",
    "\n",
    "    drop_query='''drop table if exists channels'''\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    try:\n",
    "        create_query='''create table if not exists channels(Channel_Name varchar(100),\n",
    "                            Channel_ID varchar(80) primary key,\n",
    "                            Subscribers bigint,\n",
    "                            Views bigint,\n",
    "                            Total_videos int,\n",
    "                            Channel_Description text,\n",
    "                            Playlist_Id varchar(80))'''\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "\n",
    "    except:\n",
    "        print(\"channel table already created\")\n",
    "\n",
    "\n",
    "    ch_list=[]\n",
    "    db= client[\"Youtube_data\"] #calling db in postgresql\n",
    "    coll1=db[\"channel_details\"] #calling db in mongo db\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):   #creating list to store channel details from mongodb...empty{} braces for selecting all the column from channel details\n",
    "        ch_list.append(ch_data[\"channel_information\"])                   #selecting _id =0 to negate the id value from mongodb \n",
    "\n",
    "    df=pd.DataFrame(ch_list)\n",
    "\n",
    "\n",
    "    for index,row in df.iterrows():#should have 2 variable for iteration, column name display like key ,row value as value  -->#print(index,row) #postgres column name\n",
    "        insert_query='''insert into channels(Channel_Name,   \n",
    "                                            Channel_ID,\n",
    "                                            Subscribers,\n",
    "                                            Views,\n",
    "                                            Total_videos,\n",
    "                                            Channel_Description,\n",
    "                                            Playlist_Id)\n",
    "                                            \n",
    "                                            values(%s,%s,%s,%s,%s,%s,%s)'''\n",
    "        \n",
    "        values=(row['Channel_Name'], #name are similar to df column name\n",
    "                row['Channel_ID'],\n",
    "                row['Subscribers'],\n",
    "                row['Views'],\n",
    "                row['Total_videos'],\n",
    "                row['Channel_Description'],\n",
    "                row['Playlist_Id'])\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(insert_query,values)\n",
    "            mydb.commit()\n",
    "\n",
    "        except:\n",
    "            print(\"Channel values are already inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_Name</th>\n",
       "      <th>Channel_ID</th>\n",
       "      <th>Views</th>\n",
       "      <th>Subscribers</th>\n",
       "      <th>Total_videos</th>\n",
       "      <th>Channel_Description</th>\n",
       "      <th>Playlist_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Science With Sam - ‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡ÆØ‡Æ≤‡Øç ‡ÆÖ‡Æ±‡Æø‡Æµ‡Øã‡ÆÆ‡Øç !</td>\n",
       "      <td>UChGd9JY4yMegY6PxqpBjpRA</td>\n",
       "      <td>3870827</td>\n",
       "      <td>59000</td>\n",
       "      <td>257</td>\n",
       "      <td>‡Æ®‡Ææ‡Æ©‡Øç, ‡Æá‡ÆØ‡Æ±‡Øç‡Æ™‡Æø‡ÆØ‡Æ≤‡Øç ‡Æ§‡ØÅ‡Æ±‡Øà‡ÆØ‡Æø‡Æ≤‡Øç ‡ÆÆ‡ØÅ‡Æ©‡Øà‡Æµ‡Æ∞‡Øç ‡Æ™‡Æü‡Øç‡Æü‡ÆÆ‡Øç, ‡Æú‡Æ™‡Øç‡Æ™‡Ææ...</td>\n",
       "      <td>UUhGd9JY4yMegY6PxqpBjpRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mr. GK</td>\n",
       "      <td>UC5cY198GU1MQMIPJgMkCJ_Q</td>\n",
       "      <td>195802585</td>\n",
       "      <td>1370000</td>\n",
       "      <td>496</td>\n",
       "      <td>Please contact me thru my mail id given below....</td>\n",
       "      <td>UU5cY198GU1MQMIPJgMkCJ_Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tamil Business Podcast</td>\n",
       "      <td>UCy1lBBbXhtfzugF_LK2b6Yw</td>\n",
       "      <td>727953</td>\n",
       "      <td>20900</td>\n",
       "      <td>21</td>\n",
       "      <td>Welcome to the Tamil Business Podcast, your ul...</td>\n",
       "      <td>UUy1lBBbXhtfzugF_LK2b6Yw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Channel_Name                Channel_ID      Views  \\\n",
       "0  Science With Sam - ‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡ÆØ‡Æ≤‡Øç ‡ÆÖ‡Æ±‡Æø‡Æµ‡Øã‡ÆÆ‡Øç !  UChGd9JY4yMegY6PxqpBjpRA    3870827   \n",
       "1                                 Mr. GK  UC5cY198GU1MQMIPJgMkCJ_Q  195802585   \n",
       "2                 Tamil Business Podcast  UCy1lBBbXhtfzugF_LK2b6Yw     727953   \n",
       "\n",
       "  Subscribers Total_videos                                Channel_Description  \\\n",
       "0       59000          257  ‡Æ®‡Ææ‡Æ©‡Øç, ‡Æá‡ÆØ‡Æ±‡Øç‡Æ™‡Æø‡ÆØ‡Æ≤‡Øç ‡Æ§‡ØÅ‡Æ±‡Øà‡ÆØ‡Æø‡Æ≤‡Øç ‡ÆÆ‡ØÅ‡Æ©‡Øà‡Æµ‡Æ∞‡Øç ‡Æ™‡Æü‡Øç‡Æü‡ÆÆ‡Øç, ‡Æú‡Æ™‡Øç‡Æ™‡Ææ...   \n",
       "1     1370000          496  Please contact me thru my mail id given below....   \n",
       "2       20900           21  Welcome to the Tamil Business Podcast, your ul...   \n",
       "\n",
       "                Playlist_Id  \n",
       "0  UUhGd9JY4yMegY6PxqpBjpRA  \n",
       "1  UU5cY198GU1MQMIPJgMkCJ_Q  \n",
       "2  UUy1lBBbXhtfzugF_LK2b6Yw  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating playlist table in postgresql\n",
    "def playlist_table():\n",
    "    mydb=psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"12345\",\n",
    "        database=\"youtube_data\",\n",
    "        port=5432)\n",
    "    cursor=mydb.cursor()\n",
    "\n",
    "    drop_query = '''drop table if exists playlists'''\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit\n",
    "\n",
    "    create_query='''create table if not exists playlists(Playlist_Id varchar(100) primary key,\n",
    "                                                        Title varchar(100),\n",
    "                                                        Channel_Id varchar(100),\n",
    "                                                        Channel_Name varchar(100),\n",
    "                                                        PublishedAt timestamp,\n",
    "                                                        Videocount int)'''\n",
    "\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    pl_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for pl_data in coll1.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "    #print(len(pl_data[\"playlist_information\"])) -->this provide no of records in each playlist\n",
    "        for i in range(len(pl_data[\"playlist_information\"])):\n",
    "            pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "\n",
    "    df1=pd.DataFrame(pl_list)\n",
    "\n",
    "    for index,row in df1.iterrows():#should have 2 variable for iteration, column name display like key ,row value as value  -->#print(index,row) #postgres column name \n",
    "        insert_query='''insert into playlists(Playlist_Id,\n",
    "                                                Title,\n",
    "                                                Channel_Id,\n",
    "                                                Channel_Name,\n",
    "                                                PublishedAt,\n",
    "                                                Videocount)\n",
    "                                                \n",
    "                                            values(%s,%s,%s,%s,%s,%s)'''\n",
    "        \n",
    "        values=(row['Playlist_Id'],\n",
    "                row['Title'], #name are similar to df column name\n",
    "                row['Channel_Id'],\n",
    "                row['Channel_Name'],\n",
    "                row['PublishedAt'],\n",
    "                row['Videocount'],\n",
    "                )\n",
    "        \n",
    "\n",
    "        cursor.execute(insert_query,values)\n",
    "        mydb.commit()\n",
    "\n",
    "    #pl_data[\"playlist_information\"][0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create video table in postgresql\n",
    "def video_table():\n",
    "\n",
    "    mydb=psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"12345\",\n",
    "        database=\"youtube_data\",\n",
    "        port=5432)\n",
    "    cursor=mydb.cursor()\n",
    "\n",
    "    drop_query = '''drop table if exists videos'''\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit\n",
    "\n",
    "    create_query='''create table if not exists videos(Channel_Name varchar(100),\n",
    "                                                    Channel_Id varchar(100),\n",
    "                                                    Video_Id varchar(30) primary key,\n",
    "                                                    Video_Title varchar(150),\n",
    "                                                    Tags text,\n",
    "                                                    Thumbnail varchar(200),\n",
    "                                                    Description text,\n",
    "                                                    Published_Date timestamp,\n",
    "                                                    Duration interval,\n",
    "                                                    Views bigint,\n",
    "                                                    Likes bigint,\n",
    "                                                    Comments int,\n",
    "                                                    FavoriteCount int,\n",
    "                                                    Definition varchar(10),\n",
    "                                                    Caption_Status varchar(10))'''\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    vi_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for vi_data in coll1.find({},{\"_id\":0,\"video_information\":1}):\n",
    "    #print(len(pl_data[\"playlist_information\"])) -->this provide no of records in each playlist\n",
    "        for i in range(len(vi_data[\"video_information\"])):\n",
    "            vi_list.append(vi_data[\"video_information\"][i])\n",
    "\n",
    "    df2=pd.DataFrame(vi_list)\n",
    "\n",
    "    for index,row in df2.iterrows():\n",
    "        insert_query='''insert into videos(Channel_Name,\n",
    "                                            Channel_Id,\n",
    "                                            Video_Id,\n",
    "                                            Video_Title,\n",
    "                                            Tags,\n",
    "                                            Thumbnail,\n",
    "                                            Description,\n",
    "                                            Published_Date,\n",
    "                                            Duration,\n",
    "                                            Views,\n",
    "                                            Likes,\n",
    "                                            Comments,\n",
    "                                            FavoriteCount,\n",
    "                                            Definition,\n",
    "                                            Caption_Status)\n",
    "                                            values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)'''\n",
    "        \n",
    "        values=(row['channel_Name'],\n",
    "                row['channel_Id'], \n",
    "                row['Video_Id'],\n",
    "                row['Video_Title'],\n",
    "                row['Tags'],\n",
    "                row['Thumnail'],\n",
    "                row['Description'],\n",
    "                row['Published_Date'],\n",
    "                row['Duration'], \n",
    "                row['Views'],\n",
    "                row['Likes'],\n",
    "                row['Comments'],\n",
    "                row['FavoriteCount'],\n",
    "                row['Definition'],\n",
    "                row['Caption_Status']\n",
    "                )\n",
    "    \n",
    "\n",
    "        cursor.execute(insert_query,values)\n",
    "        mydb.commit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment table creation in postgre\n",
    "\n",
    "def comments_table():\n",
    "        mydb=psycopg2.connect(\n",
    "                host=\"localhost\",\n",
    "                user=\"postgres\",\n",
    "                password=\"12345\",\n",
    "                database=\"youtube_data\",\n",
    "                port=5432)\n",
    "        cursor=mydb.cursor()\n",
    "\n",
    "        drop_query = '''drop table if exists comments'''\n",
    "        cursor.execute(drop_query)\n",
    "        mydb.commit\n",
    "\n",
    "        create_query='''create table if not exists comments(Comment_Id varchar(100) primary key,\n",
    "                                                        Video_Id varchar(100),\n",
    "                                                        Comment_Text text,\n",
    "                                                        Comment_Author varchar(150),\n",
    "                                                        Comment_Published timestamp\n",
    "                                                        )'''\n",
    "\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "\n",
    "        com_list=[]\n",
    "        db=client[\"Youtube_data\"]\n",
    "        coll1=db[\"channel_details\"]\n",
    "        for com_data in coll1.find({},{\"_id\":0,\"comment_information\":1}):\n",
    "        #print(len(pl_data[\"playlist_information\"])) -->this provide no of records in each playlist\n",
    "                for i in range(len(com_data[\"comment_information\"])):\n",
    "                        com_list.append(com_data[\"comment_information\"][i])\n",
    "\n",
    "        df3=pd.DataFrame(com_list)\n",
    "\n",
    "        for index,row in df3.iterrows():\n",
    "                insert_query='''insert into comments(Comment_Id,\n",
    "                                                        Video_Id,\n",
    "                                                        Comment_Text,\n",
    "                                                        Comment_Author,\n",
    "                                                        Comment_Published\n",
    "                                                )\n",
    "                                                        values(%s,%s,%s,%s,%s)'''\n",
    "                \n",
    "                values=(row['Comment_Id'],\n",
    "                        row['Video_Id'],\n",
    "                        row['Comment_Text'],\n",
    "                        row['Comment_Author'],\n",
    "                        row['Comment_Published'])\n",
    "\n",
    "\n",
    "                cursor.execute(insert_query,values)\n",
    "                mydb.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables():\n",
    "    channels_table()\n",
    "    playlist_table()\n",
    "    video_table()\n",
    "    comments_table()\n",
    "    \n",
    "    return \"tables created successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tables=tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channel_table():\n",
    "    ch_list=[]\n",
    "    db= client[\"Youtube_data\"] #calling db in postgresql\n",
    "    coll1=db[\"channel_details\"] #calling db in mongo db\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):   \n",
    "        ch_list.append(ch_data[\"channel_information\"])                   #selecting _id =0 to negate the id value from mongodb \n",
    "\n",
    "    df=st.dataframe(ch_list)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_playlist_table():\n",
    "    pl_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for pl_data in coll1.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "    #print(len(pl_data[\"playlist_information\"])) -->this provide no of records in each playlist\n",
    "        for i in range(len(pl_data[\"playlist_information\"])):\n",
    "            pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "\n",
    "    df1=st.dataframe(pl_list)\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video_table():\n",
    "    vi_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for vi_data in coll1.find({},{\"_id\":0,\"video_information\":1}):\n",
    "    #print(len(pl_data[\"playlist_information\"])) -->this provide no of records in each playlist\n",
    "        for i in range(len(vi_data[\"video_information\"])):\n",
    "            vi_list.append(vi_data[\"video_information\"][i])\n",
    "    \n",
    "    df2=st.dataframe(vi_list)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comments_table():\n",
    "        com_list=[]\n",
    "        db=client[\"Youtube_data\"]\n",
    "        coll1=db[\"channel_details\"]\n",
    "        for com_data in coll1.find({},{\"_id\":0,\"comment_information\":1}):\n",
    "        #print(len(pl_data[\"playlist_information\"])) -->this provide no of records in each playlist\n",
    "                for i in range(len(com_data[\"comment_information\"])):\n",
    "                        com_list.append(com_data[\"comment_information\"][i])\n",
    "\n",
    "        df3=st.dataframe(com_list)\n",
    "\n",
    "        return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stream lit\n",
    "\n",
    "with st.sidebar:\n",
    "    st.title(\":Maroon[Youtube Data Harvesting and Warehousing]\")\n",
    "    st.header(\"Skill Take Away\")\n",
    "    st.caption(\"Python Scripting\")\n",
    "    st.caption(\"Data Collection\")\n",
    "    st.caption(\"MongoDB\")\n",
    "    st.caption(\"API Integration\")\n",
    "    st.caption(\"Data Management using MongoDB and SQL\")\n",
    "\n",
    "channel_id=st.text_input(\"Enter the channel ID\")\n",
    "\n",
    "\n",
    "\n",
    "if st.button(\"collect and store data\"):\n",
    "    ch_ids=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0, \"channel_information\":1}):\n",
    "        ch_ids.append(ch_data[\"channels_information\"][\"Channel_ID\"])\n",
    "\n",
    "    if channel_id in ch_ids:\n",
    "        st.success(\"channel details of the given channel id already exists\")\n",
    "\n",
    "    else:\n",
    "        insert=channel_details(channel_id)\n",
    "        st.success(insert)\n",
    "\n",
    "if st.button(\"Migrate to Sql\"):\n",
    "    Table=tables()\n",
    "    st.success(Table)\n",
    "\n",
    "show_table=st.radio(\"Select the table for View\",(\"Channels\",\"Playlists\",\"Videos\",\"Comments\"))\n",
    "\n",
    "if show_table==\"Channels\":\n",
    "    show_channel_table()\n",
    "elif show_table==\"Playlists\":\n",
    "    show_playlist_table()\n",
    "elif show_table==\"Videos\":\n",
    "    show_video_table()\n",
    "elif show_table==\"Comments\":\n",
    "    show_comments_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL Connection\n",
    "\n",
    "mydb=psycopg2.connect(\n",
    "                host=\"localhost\",\n",
    "                user=\"postgres\",\n",
    "                password=\"12345\",\n",
    "                database=\"youtube_data\",\n",
    "                port=5432)\n",
    "cursor=mydb.cursor()\n",
    "\n",
    "question=st.selectbox(\"Select your question\",(\"1. All the videos and channel name\",\n",
    "                                              \"2. Channels with most number of videos\",\n",
    "                                              \"3. Top 10 most viewed videos\",\n",
    "                                              \"4. Comments in each videos\",\n",
    "                                              \"5. Videos with highest likes\",\n",
    "                                              \"6. Likes of all videos\",\n",
    "                                              \"7. Views of each channel\",\n",
    "                                              \"8. Videos published in the year of 2022\",\n",
    "                                              \"9. Average duration of all videos in each channel\",\n",
    "                                              \"10. Videos with highest number of comments\"))\n",
    "\n",
    "if question==\"1. All the videos and channel name\":\n",
    "    query1='''select video_title as videos,channel_name as channelname from videos'''\n",
    "    cursor.execute(query1)\n",
    "    mydb.commit\n",
    "    t1=cursor.fetchall()   #fetch the result which is stored in cursor and assigning it to a variable\n",
    "    df=pd.DataFrame(t1,columns=[\"video title\",\"channel name\"]) #converting it into df and assigning column name \n",
    "    st.write(df)\n",
    "\n",
    "\n",
    "elif question==\"2. Channels with most number of videos\":\n",
    "    query2='''select channel_name as channelname, total_videos as total_no_of_videos from channels order by total_videos desc'''\n",
    "    cursor.execute(query2)\n",
    "    mydb.commit\n",
    "    t2=cursor.fetchall()  \n",
    "    df2=pd.DataFrame(t2,columns=[\"channel name\",\"total_no_of_Videos\"]) \n",
    "    st.write(df2)\n",
    "\n",
    "elif question==\"3. Top 10 most viewed videos\":\n",
    "    query3='''select video_title as title,views as total_views,channel_name as channelname from videos \n",
    "            where views is not null order by views desc limit 10'''\n",
    "    cursor.execute(query3)\n",
    "    mydb.commit\n",
    "    t3=cursor.fetchall()  \n",
    "    df3=pd.DataFrame(t3,columns=[\"video_title\",\"views\",\"channel name\"])\n",
    "    st.write(df3)\n",
    "\n",
    "elif question==\"4. Comments in each videos\":\n",
    "    query4='''select  video_title as title,comments as total_comments from videos where comments is not null'''\n",
    "    cursor.execute(query4)\n",
    "    mydb.commit\n",
    "    t4=cursor.fetchall()   \n",
    "    df4=pd.DataFrame(t4,columns=[\"video_title\",\"comments\"]) \n",
    "    st.write(df4)\n",
    "\n",
    "elif question==\"5. Videos with highest likes\":\n",
    "    query5='''select  video_title as title,likes as no_of_likes from videos where likes is not null order by likes desc'''\n",
    "    cursor.execute(query5)\n",
    "    mydb.commit\n",
    "    t5=cursor.fetchall()   \n",
    "    df5=pd.DataFrame(t5,columns=[\"video_title\",\"likes\"]) \n",
    "    st.write(df5)\n",
    "\n",
    "elif question==\"6. Likes of all videos\":\n",
    "    query6='''select  video_title as title,likes as no_of_likes from videos '''\n",
    "    cursor.execute(query6)\n",
    "    mydb.commit\n",
    "    t6=cursor.fetchall()   \n",
    "    df6=pd.DataFrame(t6,columns=[\"video_title\",\"likes\"]) \n",
    "    st.write(df6)\n",
    "\n",
    "elif question==\"7. Views of each channel\":\n",
    "    query7='''select  channel_name as channelname,views as view_count from channels '''\n",
    "    cursor.execute(query7)\n",
    "    mydb.commit\n",
    "    t7=cursor.fetchall()   \n",
    "    df7=pd.DataFrame(t7,columns=[\"channelname\",\"viewcount\"]) \n",
    "    st.write(df7)\n",
    "\n",
    "elif question==\"8. Videos published in the year of 2022\":\n",
    "    query8='''select  video_title as video_title,published_date as videorelease,channel_name as channelname from videos \n",
    "            where extract(year from published_date)=2022'''\n",
    "    mydb.commit\n",
    "    t8=cursor.fetchall()   \n",
    "    df8=pd.DataFrame(t8,columns=[\"videotitle\",\"videoreleasedate\",\"channelname\"]) \n",
    "    st.write(df8)\n",
    "\n",
    "elif question==\"9. Average duration of all videos in each channel\":\n",
    "    query9='''select  channel_name as channelname, avg(duration) as average_duration from videos group by channel_name'''\n",
    "    cursor.execute(query9)\n",
    "    mydb.commit\n",
    "    t9=cursor.fetchall()   \n",
    "    df9=pd.DataFrame(t9,columns=[\"channelname\",\"averageduration\"]) \n",
    "    #timestamp cannot be shown in streamlit so convert it into string format\n",
    "    T9=[]\n",
    "    for index,row in df9.iterrows(): #iter through df9\n",
    "        channel_title=row[\"channelname\"]\n",
    "        average_duration=row[\"averageduration\"]\n",
    "        average_duration_str=str(average_duration)  #convert duration into string\n",
    "        T9.append(dict(channeltitle=channel_title,avgduration=average_duration_str)) #assigning column and values in dict format\n",
    "    df1=pd.DataFrame(T9)\n",
    "    st.write(df1)\n",
    "\n",
    "elif question==\"10. Videos with highest number of comments\":\n",
    "    query10='''select  video_title as Video_title,channel_name as channelname,comments as comments_count from videos where comments is not null  order by comments desc'''\n",
    "    cursor.execute(query10)\n",
    "    mydb.commit\n",
    "    t10=cursor.fetchall()   \n",
    "    df10=pd.DataFrame(t10,columns=[\"video_title\",\"channelname\",\"comments_count\"]) \n",
    "    st.write(df10)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb=psycopg2.connect(host=\"localhost\",\n",
    "                      user=\"postgres\",\n",
    "                      password=\"12345\",\n",
    "                      database=\"youtube_data\",\n",
    "                      port=\"5432\")\n",
    "cursor=mydb.cursor()\n",
    "\n",
    "#if question==\"10. Videos with highest number of comments\":\n",
    "query10='''select  video_title as Video_title,channel_name as channelname,comments as comments_count from videos where comments is not null  order by comments desc'''\n",
    "cursor.execute(query10)\n",
    "mydb.commit\n",
    "t10=cursor.fetchall()   \n",
    "df10=pd.DataFrame(t10,columns=[\"video_title\",\"channelname\",\"comments_count\"]) \n",
    "st.write(df10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_title</th>\n",
       "      <th>channelname</th>\n",
       "      <th>comments_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zee Tamil ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Ææ ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Ææ‡Æµ‡Æø‡Æ≤‡Øç ‡Æ®‡Æü‡Æ®‡Øç‡Æ§‡Æ§‡ØÅ ‡Æé‡Æ©‡Øç‡Æ©? | Tham...</td>\n",
       "      <td>Mr. GK</td>\n",
       "      <td>9723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡Æï‡Æü‡Æµ‡ØÅ‡Æ≥‡Øç ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Ææ‡Æ∞‡Ææ? ‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡ÆØ‡Æ≤‡Øç ‡Æé‡Æ©‡Øç‡Æ© ‡Æö‡Øä‡Æ≤‡Øç‡Æï‡Æø‡Æ±‡Æ§‡ØÅ?  ...</td>\n",
       "      <td>Mr. GK</td>\n",
       "      <td>6685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Logo! | My family! | RishiPedia! | 3 Surpr...</td>\n",
       "      <td>Mr. GK</td>\n",
       "      <td>6262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who am i? Real name of Mr.GK | 100th Video</td>\n",
       "      <td>Mr. GK</td>\n",
       "      <td>5754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6√∑2(1+2) = ? Viral Math Puzzle Solved! | Mr.GK</td>\n",
       "      <td>Mr. GK</td>\n",
       "      <td>4884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>PhonePe Pulse Data Visualization and Explorati...</td>\n",
       "      <td>Data Science Tamil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Tamil Business Podcast Live Stream</td>\n",
       "      <td>Tamil Business Podcast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>üî•Amazing ISRO Rocket Toys On AmazonüòÆ | Science...</td>\n",
       "      <td>Mr. GK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>21. Keeladi &amp; Nanotechnology - Scientific trut...</td>\n",
       "      <td>Science With Sam - ‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡ÆØ‡Æ≤‡Øç ‡ÆÖ‡Æ±‡Æø‡Æµ‡Øã‡ÆÆ‡Øç !</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Unknown Story behind Interstellar - in Tamil |...</td>\n",
       "      <td>Mr. GK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>804 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           video_title  \\\n",
       "0    Zee Tamil ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Ææ ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Ææ‡Æµ‡Æø‡Æ≤‡Øç ‡Æ®‡Æü‡Æ®‡Øç‡Æ§‡Æ§‡ØÅ ‡Æé‡Æ©‡Øç‡Æ©? | Tham...   \n",
       "1    ‡Æï‡Æü‡Æµ‡ØÅ‡Æ≥‡Øç ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Ææ‡Æ∞‡Ææ? ‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡ÆØ‡Æ≤‡Øç ‡Æé‡Æ©‡Øç‡Æ© ‡Æö‡Øä‡Æ≤‡Øç‡Æï‡Æø‡Æ±‡Æ§‡ØÅ?  ...   \n",
       "2    New Logo! | My family! | RishiPedia! | 3 Surpr...   \n",
       "3           Who am i? Real name of Mr.GK | 100th Video   \n",
       "4       6√∑2(1+2) = ? Viral Math Puzzle Solved! | Mr.GK   \n",
       "..                                                 ...   \n",
       "799  PhonePe Pulse Data Visualization and Explorati...   \n",
       "800                 Tamil Business Podcast Live Stream   \n",
       "801  üî•Amazing ISRO Rocket Toys On AmazonüòÆ | Science...   \n",
       "802  21. Keeladi & Nanotechnology - Scientific trut...   \n",
       "803  Unknown Story behind Interstellar - in Tamil |...   \n",
       "\n",
       "                               channelname  comments_count  \n",
       "0                                   Mr. GK            9723  \n",
       "1                                   Mr. GK            6685  \n",
       "2                                   Mr. GK            6262  \n",
       "3                                   Mr. GK            5754  \n",
       "4                                   Mr. GK            4884  \n",
       "..                                     ...             ...  \n",
       "799                     Data Science Tamil               1  \n",
       "800                 Tamil Business Podcast               0  \n",
       "801                                 Mr. GK               0  \n",
       "802  Science With Sam - ‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡ÆØ‡Æ≤‡Øç ‡ÆÖ‡Æ±‡Æø‡Æµ‡Øã‡ÆÆ‡Øç !               0  \n",
       "803                                 Mr. GK               0  \n",
       "\n",
       "[804 rows x 3 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
